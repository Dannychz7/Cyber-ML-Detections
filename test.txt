import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, FunctionTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import joblib

trainPath = "/Users/danielchavez/Downloads/Courses/MohsinResearch/Neural Networks/train.csv"

# 1. Data Loading
df = pd.read_csv(trainPath).replace('NA', np.nan)

# 2. Target Transformation Setup
def preprocess_features(df):
    """Feature engineering that applies to both train and test data"""
    # Age features
    df['HouseAge'] = df['YrSold'] - df['YearBuilt']
    df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']
    df['GarageAge'] = df['YrSold'] - df['GarageYrBlt']
    
    # Area features
    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']
    df['TotalBathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + 
                          df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))
    
    # Binary features
    df['HasSecondFloor'] = (df['2ndFlrSF'] > 0).astype(int)
    df['HasPool'] = (df['PoolArea'] > 0).astype(int)
    
    return df

# 3. Define Feature Types
numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = df.select_dtypes(include=['object']).columns.tolist()

# Remove special columns
for col in ['Id', 'SalePrice']:
    if col in numeric_features:
        numeric_features.remove(col)
    if col in categorical_features:
        categorical_features.remove(col)

# 4. Preprocessing Pipeline
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 5. Full Pipeline with Target Transformation
model = Pipeline(steps=[
    ('preprocess', FunctionTransformer(preprocess_features)),
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
])

# 6. Prepare Data
X = df.drop(['Id', 'SalePrice'], axis=1)
y = np.log1p(df['SalePrice'])  # Log transform target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Train Model
model.fit(X_train, y_train)

# 8. Evaluate
train_preds = np.expm1(model.predict(X_train))
test_preds = np.expm1(model.predict(X_test))

print(f"Train R2: {r2_score(np.expm1(y_train), train_preds):.4f}")
print(f"Test R2: {r2_score(np.expm1(y_test), test_preds):.4f}")

# 9. Save Model Package
model_package = {
    'pipeline': model,
    'expected_columns': X.columns.tolist(),
    'log_target': True  # Flag indicating we log-transformed target
}

joblib.dump(model_package, 'house_price_pipeline.pkl')
print("âœ… Model saved with all preprocessing metadata")